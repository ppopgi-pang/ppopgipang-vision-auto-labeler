{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Vision Pipeline - Google Colab 컨트롤러\n\n이 노트북을 사용하면 Google Colab에서 GPU를 사용하여 vision pipeline을 실행할 수 있습니다.\nGoogle Drive를 마운트하여 저장 공간으로 사용하고 자동으로 환경을 설정합니다."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 1. 환경 설정"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# @title 리포지토리 클론 및 의존성 설치\nimport os\n\n# --- Configuration ---\nREPO_URL = \"https://github.com/ppopgi-pang/ppopgipang-vision-auto-labeler.git\" # @param {type:\"string\"}\nBRANCH = \"main\" # @param {type:\"string\"}\n# ---------------------\n\n# 리포지토리 클론\nrepo_name = REPO_URL.split(\"/\")[-1].replace(\".git\", \"\")\nif not os.path.exists(repo_name):\n    print(f\"Cloning {REPO_URL}...\")\n    !git clone {REPO_URL}\nelse:\n    print(f\"Repository {repo_name} already exists.\")\n\n# 프로젝트 디렉토리로 이동\n%cd {repo_name}\n\n# 의존성 설치\nprint(\"Installing dependencies...\")\nif os.path.exists(\"requirements.txt\"):\n    !pip install -r requirements.txt\nelse:\n    print(\"requirements.txt not found, installing default dependencies...\")\n    # Fallback based on pyproject.toml inspection\n    !pip install pyyaml pydantic pydantic-settings python-dotenv requests pillow numpy opencv-python-headless ImageHash\n    !pip install torch torchvision transformers ultralytics openai playwright nest_asyncio\n\nprint(\"Playwright용 시스템 의존성 설치...\")\n!apt-get update\n!apt-get install -y libatk1.0-0 libatk-bridge2.0-0 libgtk-3-0 libnss3 libx11-xcb1 \\\n  libxcomposite1 libxdamage1 libxrandr2 libgbm1 libasound2 libpangocairo-1.0-0 \\\n  libpango-1.0-0 libcups2 libdrm2 libxkbcommon0 libxfixes3 libxfext6\nprint(\"Playwright 브라우저 설치...\")\n!playwright install chromium\n\nprint(\"Done.\")"
  },
  {
   "cell_type": "markdown",
   "id": "52159a2e",
   "metadata": {},
   "source": "## 1.1 API 키 설정\n**중요:** 프로젝트 모듈을 import하기 전에 이 셀을 실행하여 키가 올바르게 로드되도록 하세요."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35aba41e",
   "metadata": {},
   "outputs": [],
   "source": "import os\n\n# @markdown ### API 키\n# @markdown API 키를 여기에 입력하세요. 크롤링 및 LLM 검증에 필요합니다.\nimport os\nfrom google.colab import userdata\n\nOPENAI_API_KEY = userdata.get(\"OPENAI_API_KEY\")\n\n# 환경 변수에 주입\nos.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n\n# 유효성 검증 경고\nif \"YOUR_\" in OPENAI_API_KEY:\n    print(\"WARNING: OPENAI_API_KEY에 기본 플레이스홀더가 감지되었습니다. 실제 키로 업데이트하세요.\")\n    \nprint(\"환경 변수 설정 완료.\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 2. GPU 확인"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import torch\n\nif torch.cuda.is_available():\n    print(f\"SUCCESS: GPU 사용 가능 - {torch.cuda.get_device_name(0)}\")\nelse:\n    print(\"WARNING: GPU를 찾을 수 없습니다. Runtime > Change runtime type > Hardware accelerator > GPU에서 활성화하세요.\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 3. Google Drive 마운트 및 경로 설정"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from google.colab import drive\nimport sys\nimport os\n\n# Drive 마운트\ndrive.mount('/content/drive')\n\n# 경로 설정\nPROJECT_ROOT = os.getcwd()\nif PROJECT_ROOT not in sys.path:\n    sys.path.append(PROJECT_ROOT)\n    print(f\"Added {PROJECT_ROOT} to sys.path\")\n\n# 중요: vision_pipeline을 sys.path에 추가하여 'pipelines', 'domain' 등에서 import 가능하도록 함\nPIPELINE_ROOT = os.path.join(PROJECT_ROOT, 'vision_pipeline')\nif PIPELINE_ROOT not in sys.path:\n    sys.path.append(PIPELINE_ROOT)\n    print(f\"Added {PIPELINE_ROOT} to sys.path\")\n\n# Drive에 출력 디렉토리 설정\nBASE_OUTPUT_DIR = \"/content/drive/MyDrive/vision_pipeline_data\" # @param {type:\"string\"}\nos.makedirs(BASE_OUTPUT_DIR, exist_ok=True)\n\n# config.py 기본값을 오버라이드하기 위한 환경 변수 설정\nos.environ[\"OUTPUT_DIR\"] = BASE_OUTPUT_DIR\nprint(f\"출력 디렉토리 설정: {BASE_OUTPUT_DIR}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 4. 파이프라인 실행"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import nest_asyncio\nnest_asyncio.apply()\n\nfrom vision_pipeline.domain.job import Job\nfrom vision_pipeline.services.pipeline_runner import PipelineRunner\nfrom vision_pipeline.config import settings\nimport logging\n\n# --- 실행 설정 ---\nKEYWORDS = \"anime character doll, anime figure doll, anime plush doll, anime character plush, anime collectible doll, anime vinyl figure, anime chibi doll, anime character toy, anime action figure, anime mascot doll, アニメ キャラクター 人形, アニメ フィギュア, アニメ ぬいぐるみ, キャラクター フィギュア, キャラクター ぬいぐるみ, 美少女 フィギュア, デフォルメ フィギュア, アニメ グッズ 人形, キャラクター ドール, フィギュア 写真, 애니 캐릭터 인형, 애니 피규어, 캐릭터 인형, 캐릭터 피규어, 애니메이션 인형, 애니 굿즈 인형, 캐릭터 굿즈 피규어, 미소녀 피규어, SD 피규어, 애니 캐릭터 장난감, anime doll figure, anime plush toy, anime figure collection, anime doll collection, anime figure photography, anime toy figure, anime doll toy, anime character merchandise doll, anime figure close up, anime doll product photo, anime figure real photo, anime doll real life, anime figure unboxing, anime figure review, anime plush doll photo, anime figure shelf, anime figure display, anime doll collection photo, anime figure product shot, anime figure desk setup, anime plush, anime stuffed doll, character plush doll, anime soft toy, anime mascot plush, anime plush collection, character plush toy, anime doll plush, anime plush figure, anime plush photo, anime scale figure, anime PVC figure, anime resin figure, anime Nendoroid, anime garage kit, anime action figure toy, anime figure model, anime collectible figure, anime statue figure, anime figure closeup, Japanese character doll, Japanese anime figure, otaku figure collection, otaku room figure, anime goods figure, anime hobby figure, anime character merchandise, anime toy collection, anime doll merchandise, anime figure goods, anime doll photo site:jp, anime figure photo site:jp, アニメ フィギュア 写真, キャラクター 人形 写真, anime plush photo site:jp, フィギュア 実物 写真, anime figure blog, anime doll review blog, フィギュア レビュー, アニメ グッズ 写真\" # @param {type:\"string\"}\nTARGET_OBJECT = \"doll\" # @param {type:\"string\"}\nLIMIT = 50000 # @param {type:\"integer\"}\n\n# 키워드 파싱 (공백으로 구분하거나, 선호하는 경우 단일 구문으로 처리)\n# CLI는 여러 인수를 리스트로 처리. 여기서는 하나의 문자열을 받아 필요시 분할하거나\n# 단순히 리스트로 래핑.\nkeyword_list = [k.strip() for k in KEYWORDS.split(',') if k.strip()]\nif not keyword_list:\n    keyword_list = [KEYWORDS]\n\nprint(f\"처리 중인 키워드: {keyword_list}\")\nprint(f\"대상 객체: {TARGET_OBJECT}\")\nprint(f\"제한: {LIMIT}\")\nprint(f\"저장 경로: {settings.output_dir}\")\n\ndef run_pipeline():\n    # Job ID 생성\n    first_kw = keyword_list[0].replace(' ', '_')\n    job_id = f\"job_{TARGET_OBJECT}_{first_kw}\"\n    \n    # 기존 작업 데이터 확인하여 실수로 덮어쓰기/재실행 방지\n    # (파이프라인 로직 자체가 건너뛰기를 이상적으로 처리하지만 경고)\n    job_path = os.path.join(settings.output_dir, job_id)\n    if os.path.exists(job_path):\n        print(f\"\\n[INFO] 작업 디렉토리 {job_path}가 이미 존재합니다. 파이프라인이 재개하거나 완료된 단계를 건너뛰려고 시도합니다.\")\n    \n    # Job 생성\n    job = Job(\n        keywords=keyword_list,\n        target_class=TARGET_OBJECT,\n        limit=LIMIT,\n        job_id=job_id\n    )\n    \n    # 실행\n    runner = PipelineRunner()\n    try:\n        runner.run(job)\n        print(\"\\n대성공! 파이프라인이 완료되었습니다.\")\n    except Exception as e:\n        print(f\"\\n[ERROR] 파이프라인 실패: {e}\")\n        logging.exception(\"Pipeline Failure\")\n\n# 실행\nif __name__ == \"__main__\":\n    run_pipeline()"
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}