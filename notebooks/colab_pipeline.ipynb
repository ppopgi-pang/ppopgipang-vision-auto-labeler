{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vision Pipeline - Google Colab 컨트롤러\n",
    "\n",
    "이 노트북을 사용하면 Google Colab에서 GPU를 사용하여 vision pipeline을 실행할 수 있습니다.\n",
    "Google Drive를 마운트하여 저장 공간으로 사용하고 자동으로 환경을 설정합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 환경 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9c82b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Clone Repository & Install Dependencies (Colab-safe)\n",
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "# --- Configuration ---\n",
    "REPO_URL = \"https://github.com/ppopgi-pang/ppopgipang-vision-auto-labeler.git\"  # @param {type:\"string\"}\n",
    "BRANCH = \"main\"  # @param {type:\"string\"}\n",
    "# ---------------------\n",
    "\n",
    "\n",
    "def run_cmd(cmd):\n",
    "    print(\"+\", \" \".join(cmd))\n",
    "    subprocess.run(cmd, check=True)\n",
    "\n",
    "\n",
    "# 1. Install system dependencies + Playwright (FIRST)\n",
    "print(\"Installing Playwright and system dependencies...\")\n",
    "run_cmd([sys.executable, \"-m\", \"playwright\", \"install\", \"--with-deps\", \"chromium\"])\n",
    "\n",
    "# 2. Clone repository into a stable base directory\n",
    "repo_name = REPO_URL.split(\"/\")[-1].replace(\".git\", \"\")\n",
    "BASE_DIR = \"/content\"\n",
    "if not os.path.exists(BASE_DIR):\n",
    "    BASE_DIR = os.getcwd()\n",
    "repo_path = os.path.join(BASE_DIR, repo_name)\n",
    "\n",
    "if not os.path.exists(repo_path):\n",
    "    print(f\"Cloning {REPO_URL} into {repo_path}...\")\n",
    "    run_cmd([\"git\", \"clone\", \"-b\", BRANCH, REPO_URL, repo_path])\n",
    "else:\n",
    "    print(f\"Repository already exists at {repo_path}.\")\n",
    "\n",
    "# 3. Move into the project directory\n",
    "os.chdir(repo_path)\n",
    "\n",
    "# 4. Install Python dependencies\n",
    "print(\"Installing Python dependencies...\")\n",
    "if os.path.exists(\"requirements.txt\"):\n",
    "    run_cmd([sys.executable, \"-m\", \"pip\", \"install\", \"-r\", \"requirements.txt\"])\n",
    "else:\n",
    "    print(\"requirements.txt not found, installing fallback dependencies...\")\n",
    "    fallback_packages = [\n",
    "        \"pyyaml\",\n",
    "        \"pydantic\",\n",
    "        \"pydantic-settings\",\n",
    "        \"python-dotenv\",\n",
    "        \"requests\",\n",
    "        \"pillow\",\n",
    "        \"numpy\",\n",
    "        \"opencv-python-headless\",\n",
    "        \"ImageHash\",\n",
    "        \"torch\",\n",
    "        \"torchvision\",\n",
    "        \"transformers\",\n",
    "        \"ultralytics\",\n",
    "        \"openai\",\n",
    "        \"playwright\",\n",
    "        \"nest_asyncio\",\n",
    "    ]\n",
    "    run_cmd([sys.executable, \"-m\", \"pip\", \"install\", *fallback_packages])\n",
    "\n",
    "print(\"Setup completed successfully.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52159a2e",
   "metadata": {},
   "source": [
    "## 1.1 API 키 설정\n",
    "**중요:** 프로젝트 모듈을 import하기 전에 이 셀을 실행하여 키가 올바르게 로드되도록 하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35aba41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# @markdown ### API 키\n",
    "# @markdown API 키를 여기에 입력하세요. 크롤링 및 LLM 검증에 필요합니다.\n",
    "import os\n",
    "from google.colab import userdata\n",
    "\n",
    "OPENAI_API_KEY = userdata.get(\"OPENAI_API_KEY\")\n",
    "\n",
    "# 환경 변수에 주입\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
    "\n",
    "# 유효성 검증 경고\n",
    "if \"YOUR_\" in OPENAI_API_KEY:\n",
    "    print(\"WARNING: OPENAI_API_KEY에 기본 플레이스홀더가 감지되었습니다. 실제 키로 업데이트하세요.\")\n",
    "    \n",
    "print(\"환경 변수 설정 완료.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. GPU 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"SUCCESS: GPU 사용 가능 - {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"WARNING: GPU를 찾을 수 없습니다. Runtime > Change runtime type > Hardware accelerator > GPU에서 활성화하세요.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Google Drive 마운트 및 경로 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Drive 마운트 (종료 후 결과 복사용)\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# 경로 설정\n",
    "PROJECT_ROOT = os.getcwd()\n",
    "if PROJECT_ROOT not in sys.path:\n",
    "    sys.path.append(PROJECT_ROOT)\n",
    "    print(f\"Added {PROJECT_ROOT} to sys.path\")\n",
    "\n",
    "# 중요: vision_pipeline을 sys.path에 추가하여 'pipelines', 'domain' 등에서 import 가능하도록 함\n",
    "PIPELINE_ROOT = os.path.join(PROJECT_ROOT, 'vision_pipeline')\n",
    "if PIPELINE_ROOT not in sys.path:\n",
    "    sys.path.append(PIPELINE_ROOT)\n",
    "    print(f\"Added {PIPELINE_ROOT} to sys.path\")\n",
    "\n",
    "# 로컬 출력 디렉토리 (실행 중)\n",
    "LOCAL_OUTPUT_DIR = \"/content/vision_pipeline_data\"  # @param {type:\"string\"}\n",
    "os.makedirs(LOCAL_OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Drive로 이동할 최종 출력 디렉토리\n",
    "DRIVE_OUTPUT_DIR = \"/content/drive/MyDrive/vision_pipeline_data\"  # @param {type:\"string\"}\n",
    "\n",
    "# config.py 기본값을 오버라이드하기 위한 환경 변수 설정\n",
    "os.environ[\"OUTPUT_DIR\"] = LOCAL_OUTPUT_DIR\n",
    "print(f\"로컬 출력 디렉토리 설정: {LOCAL_OUTPUT_DIR}\")\n",
    "print(f\"Drive 출력 디렉토리(종료 후 복사): {DRIVE_OUTPUT_DIR}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 파이프라인 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52569ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import tarfile\n",
    "import time\n",
    "\n",
    "from vision_pipeline.domain.job import Job\n",
    "from vision_pipeline.services.pipeline_runner import PipelineRunner\n",
    "from vision_pipeline.config import settings\n",
    "import logging\n",
    "\n",
    "LOCAL_OUTPUT_DIR = os.environ.get(\"OUTPUT_DIR\", \"/content/vision_pipeline_data\")\n",
    "DRIVE_OUTPUT_DIR = globals().get(\"DRIVE_OUTPUT_DIR\", \"/content/drive/MyDrive/vision_pipeline_data\")\n",
    "\n",
    "# --- 실행 설정 ---\n",
    "KEYWORDS = \"anime character doll, anime figure doll, anime plush doll, anime character plush, anime collectible doll, anime vinyl figure, anime chibi doll, anime character toy, anime action figure, anime mascot doll, アニメ キャラクター 人形, アニメ フィギュア, アニメ ぬいぐるみ, キャラクター フィギュア, キャラクター ぬいぐるみ, 美少女 フィギュア, デフォルメ フィギュア, アニメ グッズ 人形, キャラクター ドール, フィギュア 写真, 애니 캐릭터 인형, 애니 피규어, 캐릭터 인형, 캐릭터 피규어, 애니메이션 인형, 애니 굿즈 인형, 캐릭터 굿즈 피규어, 미소녀 피규어, SD 피규어, 애니 캐릭터 장난감, anime doll figure, anime plush toy, anime figure collection, anime doll collection, anime figure photography, anime toy figure, anime doll toy, anime character merchandise doll, anime figure close up, anime doll product photo, anime figure real photo, anime doll real life, anime figure unboxing, anime figure review, anime plush doll photo, anime figure shelf, anime figure display, anime doll collection photo, anime figure product shot, anime figure desk setup, anime plush, anime stuffed doll, character plush doll, anime soft toy, anime mascot plush, anime plush collection, character plush toy, anime doll plush, anime plush figure, anime plush photo, anime scale figure, anime PVC figure, anime resin figure, anime Nendoroid, anime garage kit, anime action figure toy, anime figure model, anime collectible figure, anime statue figure, anime figure closeup, Japanese character doll, Japanese anime figure, otaku figure collection, otaku room figure, anime goods figure, anime hobby figure, anime character merchandise, anime toy collection, anime doll merchandise, anime figure goods, anime doll photo site:jp, anime figure photo site:jp, アニメ フィギュア 写真, キャラクター 人形 写真, anime plush photo site:jp, フィギュア 実物 写真, anime figure blog, anime doll review blog, フィギュア レビュー, アニメ グッズ 写真\" # @param {type:\"string\"}\n",
    "TARGET_OBJECT = \"doll\" # @param {type:\"string\"}\n",
    "LIMIT = 50000 # @param {type:\"integer\"}\n",
    "\n",
    "# 키워드 파싱 (공백으로 구분하거나, 선호하는 경우 단일 구문으로 처리)\n",
    "# CLI는 여러 인수를 리스트로 처리. 여기서는 하나의 문자열을 받아 필요시 분할하거나\n",
    "# 단순히 리스트로 래핑.\n",
    "keyword_list = [k.strip() for k in KEYWORDS.split(',') if k.strip()]\n",
    "if not keyword_list:\n",
    "    keyword_list = [KEYWORDS]\n",
    "\n",
    "print(f\"처리 중인 키워드: {keyword_list}\")\n",
    "print(f\"대상 객체: {TARGET_OBJECT}\")\n",
    "print(f\"제한: {LIMIT}\")\n",
    "print(f\"저장 경로: {settings.output_dir}\")\n",
    "\n",
    "def export_results(job_id: str):\n",
    "    if not os.path.isdir(LOCAL_OUTPUT_DIR) and not os.path.isdir(\"data\"):\n",
    "        print(\"[WARN] 로컬 출력 디렉토리와 data/가 모두 없습니다. 내보내기를 건너뜁니다.\")\n",
    "        return\n",
    "\n",
    "    os.makedirs(DRIVE_OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "    timestamp = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "    archive_name = f\"{job_id}_{timestamp}.tar.gz\"\n",
    "    archive_path = os.path.join(\"/content\", archive_name)\n",
    "\n",
    "    print(f\"로컬 결과 압축 중... {archive_path}\")\n",
    "    with tarfile.open(archive_path, \"w:gz\") as tar:\n",
    "        if os.path.isdir(LOCAL_OUTPUT_DIR):\n",
    "            local_base = os.path.basename(LOCAL_OUTPUT_DIR.rstrip('/'))\n",
    "            tar.add(LOCAL_OUTPUT_DIR, arcname=local_base)\n",
    "        if os.path.isdir(\"data\"):\n",
    "            tar.add(\"data\", arcname=\"data\")\n",
    "\n",
    "    drive_archive = os.path.join(DRIVE_OUTPUT_DIR, archive_name)\n",
    "    shutil.copy2(archive_path, drive_archive)\n",
    "    print(f\"Drive로 압축본 복사 완료: {drive_archive}\")\n",
    "\n",
    "def run_pipeline():\n",
    "    # Job ID 생성\n",
    "    first_kw = keyword_list[0].replace(' ', '_')\n",
    "    job_id = f\"job_{TARGET_OBJECT}_{first_kw}\"\n",
    "    \n",
    "    # 기존 작업 데이터 확인하여 실수로 덮어쓰기/재실행 방지\n",
    "    # (파이프라인 로직 자체가 건너뛰기를 이상적으로 처리하지만 경고)\n",
    "    job_path = os.path.join(settings.output_dir, job_id)\n",
    "    if os.path.exists(job_path):\n",
    "        print(f\"\\n[INFO] 작업 디렉토리 {job_path}가 이미 존재합니다. 파이프라인이 재개하거나 완료된 단계를 건너뛰려고 시도합니다.\")\n",
    "    \n",
    "    # Job 생성\n",
    "    job = Job(\n",
    "        keywords=keyword_list,\n",
    "        target_class=TARGET_OBJECT,\n",
    "        limit=LIMIT,\n",
    "        job_id=job_id\n",
    "    )\n",
    "    \n",
    "    # 실행\n",
    "    runner = PipelineRunner()\n",
    "    try:\n",
    "        runner.run(job)\n",
    "        print(\"\\n대성공! 파이프라인이 완료되었습니다.\")\n",
    "        return True, job_id\n",
    "    except Exception as e:\n",
    "        print(f\"\\n[ERROR] 파이프라인 실패: {e}\")\n",
    "        logging.exception(\"Pipeline Failure\")\n",
    "        return False, job_id\n",
    "\n",
    "# 실행\n",
    "if __name__ == \"__main__\":\n",
    "    ok, job_id = run_pipeline()\n",
    "    if ok:\n",
    "        export_results(job_id)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
