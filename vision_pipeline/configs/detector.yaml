model_path: "models/yolov8n.pt"  # provided by user
conf_threshold: 0.5
classes: null  # null for all classes, or list [0, 1, 2] for person, bicycle, car etc.
save_crops: true
crop_padding: 0
batch_size: 16  # YOLO batch processing (8-16 recommended for T4)

# Debug visualization (annotated images)
save_annotated: true
annotated_dir: "data/annotated"
annotated_box_color: [0, 255, 0]
annotated_line_width: 2
annotated_font_size: 14
annotated_show_confidence: true

# VLM labeler (for free-form class labels)
use_vlm_labeler: true
labeler_fallback_label: "unknown"
labeler:
  model: "gpt-4o"
  max_tokens: 100
  temperature: 0.0
  rate_limit_delay: 0.0  # Delay between labeler calls (seconds)
  rate_limit_max_retries: 2  # Retries on rate limit (429)
  rate_limit_retry_default_delay: 1.0  # Fallback delay if no retry hint (seconds)
  default_label: "unknown"
  api_max_concurrent: 2
  system_prompt: |
    You are a final character selection judge.
    You will receive a JSON task and an image.
    Choose exactly one label from the candidates in the JSON.
    If uncertain, choose "unknown".
    Respond with JSON only: {"label":"<candidate>"}

clip_candidate:
  enabled: true
  model_name: "openai/clip-vit-base-patch32"
  device: "auto"
  top_k: 5
  top1_threshold: 0.55
  prompt_templates:
    - "a plush toy of {character_name}"
    - "a stuffed doll representing {character_name}"
  labels_path: "configs/character_labels.yaml"
  cache_path: "data/artifacts/clip_text_embeddings.pt"
  text_batch_size: 64
  max_concurrent: 1
