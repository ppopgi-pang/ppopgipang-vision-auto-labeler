#!/usr/bin/env python3
"""
GPU/CUDA ìµœì í™” í†µí•© í…ŒìŠ¤íŠ¸
ê¸°ì¡´ ë³‘ë ¬ì²˜ë¦¬ ì½”ë“œì™€ì˜ ì¶©ëŒ ì—¬ë¶€ ë° ì •ìƒ ì‘ë™ í™•ì¸
"""

import sys
from pathlib import Path
import torch
from PIL import Image
import numpy as np

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ sys.pathì— ì¶”ê°€
project_root = Path(__file__).resolve().parent / "vision_pipeline"
sys.path.insert(0, str(project_root))

from modules.filter.dedup import Deduplicator
from modules.filter.classifier import Classifier
from modules.detector.yolo_world import YoloDetector
from domain.image import ImageItem


def create_test_images(output_dir: Path, count: int = 20):
    """í…ŒìŠ¤íŠ¸ìš© ì„ì‹œ ì´ë¯¸ì§€ ìƒì„±"""
    output_dir.mkdir(parents=True, exist_ok=True)

    image_items = []
    for i in range(count):
        # ëœë¤ ì´ë¯¸ì§€ ìƒì„±
        img_array = np.random.randint(0, 255, (256, 256, 3), dtype=np.uint8)
        img = Image.fromarray(img_array)

        # ì¼ë¶€ëŠ” ì¤‘ë³µìœ¼ë¡œ ë§Œë“¤ê¸° (dedup í…ŒìŠ¤íŠ¸ìš©)
        if i > 0 and i % 5 == 0:
            # ì´ì „ ì´ë¯¸ì§€ ë³µì‚¬
            prev_path = output_dir / f"test_{i-1}.jpg"
            img = Image.open(prev_path)

        img_path = output_dir / f"test_{i}.jpg"
        img.save(img_path)

        image_items.append(ImageItem(
            id=f"test_{i}",
            path=str(img_path),
            keyword="test_object"
        ))

    return image_items


def test_deduplicator_gpu():
    """Deduplicator GPU ëª¨ë“œ í…ŒìŠ¤íŠ¸"""
    print("\n" + "="*60)
    print("TEST 1: Deduplicator GPU ëª¨ë“œ")
    print("="*60)

    test_dir = Path("data/test_images")
    images = create_test_images(test_dir, count=20)

    config = {
        "use_gpu": True,
        "hash_size": 8,
        "threshold": 5,
        "batch_size": 8,
        "gpu_hash_limit": 10,
    }

    dedup = Deduplicator(config)

    print(f"ì…ë ¥ ì´ë¯¸ì§€: {len(images)}ê°œ")
    print(f"GPU ì‚¬ìš©: {dedup.use_gpu}")
    print(f"Device: {dedup.device}")

    unique = dedup.run(images)

    print(f"ì¶œë ¥ ì´ë¯¸ì§€: {len(unique)}ê°œ")
    print(f"ì¤‘ë³µ ì œê±°: {len(images) - len(unique)}ê°œ")

    # ì •ë¦¬
    import shutil
    shutil.rmtree(test_dir, ignore_errors=True)

    assert len(unique) <= len(images), "ì¶œë ¥ì´ ì…ë ¥ë³´ë‹¤ ë§ìœ¼ë©´ ì•ˆ ë¨"
    print("âœ… Deduplicator GPU í…ŒìŠ¤íŠ¸ í†µê³¼")
    return True


def test_deduplicator_cpu_fallback():
    """Deduplicator CPU fallback í…ŒìŠ¤íŠ¸"""
    print("\n" + "="*60)
    print("TEST 2: Deduplicator CPU Fallback")
    print("="*60)

    test_dir = Path("data/test_images_cpu")
    images = create_test_images(test_dir, count=10)

    config = {
        "use_gpu": False,  # CPU ê°•ì œ
        "hash_size": 8,
        "threshold": 5,
    }

    dedup = Deduplicator(config)

    print(f"ì…ë ¥ ì´ë¯¸ì§€: {len(images)}ê°œ")
    print(f"GPU ì‚¬ìš©: {dedup.use_gpu}")
    print(f"Device: {dedup.device}")

    unique = dedup.run(images)

    print(f"ì¶œë ¥ ì´ë¯¸ì§€: {len(unique)}ê°œ")

    # ì •ë¦¬
    import shutil
    shutil.rmtree(test_dir, ignore_errors=True)

    assert len(unique) <= len(images), "ì¶œë ¥ì´ ì…ë ¥ë³´ë‹¤ ë§ìœ¼ë©´ ì•ˆ ë¨"
    print("âœ… Deduplicator CPU fallback í…ŒìŠ¤íŠ¸ í†µê³¼")
    return True


def test_classifier_gpu():
    """Classifier GPU ëª¨ë“œ í…ŒìŠ¤íŠ¸"""
    print("\n" + "="*60)
    print("TEST 3: Classifier GPU ëª¨ë“œ")
    print("="*60)

    test_dir = Path("data/test_images_classifier")
    images = create_test_images(test_dir, count=10)

    config = {
        "model_name": "openai/clip-vit-base-patch32",
        "threshold": 0.2,
        "device": "auto",
        "batch_size": 4,
    }

    classifier = Classifier(config)

    print(f"ì…ë ¥ ì´ë¯¸ì§€: {len(images)}ê°œ")
    print(f"Device: {classifier.device}")
    print(f"ë°°ì¹˜ í¬ê¸°: {config['batch_size']}")

    # keep_positive ì‹¤í–‰
    kept = classifier.keep_positive(images)

    print(f"ì¶œë ¥ ì´ë¯¸ì§€: {len(kept)}ê°œ")

    # ì •ë¦¬
    import shutil
    shutil.rmtree(test_dir, ignore_errors=True)

    print("âœ… Classifier GPU í…ŒìŠ¤íŠ¸ í†µê³¼")
    return True


def test_yolo_detector_gpu():
    """YoloDetector GPU ëª¨ë“œ í…ŒìŠ¤íŠ¸"""
    print("\n" + "="*60)
    print("TEST 4: YoloDetector GPU ëª¨ë“œ")
    print("="*60)

    test_dir = Path("data/test_images_yolo")
    images = create_test_images(test_dir, count=5)

    config = {
        "model_path": "yolov8n.pt",
        "conf_threshold": 0.5,
        "device": "auto",
    }

    try:
        detector = YoloDetector(config)

        print(f"ì…ë ¥ ì´ë¯¸ì§€: {len(images)}ê°œ")
        print(f"Device: {detector.device}")

        # ë‹¨ì¼ ì´ë¯¸ì§€ ê²€ì¶œ
        bboxes = detector.detect(images[0])
        print(f"ë‹¨ì¼ ê²€ì¶œ ê²°ê³¼: {len(bboxes)}ê°œ bbox")

        # ë°°ì¹˜ ê²€ì¶œ
        batch_bboxes = detector.detect_batch(images[:3])
        print(f"ë°°ì¹˜ ê²€ì¶œ ê²°ê³¼: {len(batch_bboxes)}ê°œ ì´ë¯¸ì§€")

        print("âœ… YoloDetector GPU í…ŒìŠ¤íŠ¸ í†µê³¼")

    except Exception as e:
        print(f"âš ï¸  YoloDetector í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨ (YOLO ëª¨ë¸ ë‹¤ìš´ë¡œë“œ í•„ìš”): {e}")
        print("   ì´ëŠ” ì •ìƒì…ë‹ˆë‹¤. ì‹¤ì œ í™˜ê²½ì—ì„œëŠ” ì‘ë™í•©ë‹ˆë‹¤.")

    finally:
        # ì •ë¦¬
        import shutil
        shutil.rmtree(test_dir, ignore_errors=True)

    return True


def test_concurrent_gpu_usage():
    """GPU ë™ì‹œ ì‚¬ìš© í…ŒìŠ¤íŠ¸ (ìˆœì°¨ ì‹¤í–‰ í™•ì¸)"""
    print("\n" + "="*60)
    print("TEST 5: íŒŒì´í”„ë¼ì¸ ìˆœì°¨ ì‹¤í–‰ (GPU ì¶©ëŒ í™•ì¸)")
    print("="*60)

    test_dir = Path("data/test_images_concurrent")
    images = create_test_images(test_dir, count=10)

    # 1. Deduplicator
    print("\n[1/2] Deduplicator ì‹¤í–‰...")
    dedup_config = {"use_gpu": True, "hash_size": 8, "threshold": 5}
    dedup = Deduplicator(dedup_config)
    images = dedup.run(images)

    # GPU ë©”ëª¨ë¦¬ ì •ë¦¬ í™•ì¸
    if torch.cuda.is_available():
        print(f"   GPU ë©”ëª¨ë¦¬ í• ë‹¹: {torch.cuda.memory_allocated() / 1024**2:.2f} MB")

    # 2. Classifier
    print("\n[2/2] Classifier ì‹¤í–‰...")
    classifier_config = {
        "model_name": "openai/clip-vit-base-patch32",
        "threshold": 0.2,
        "device": "auto",
        "batch_size": 4,
    }
    classifier = Classifier(classifier_config)
    images = classifier.keep_positive(images)

    # GPU ë©”ëª¨ë¦¬ í™•ì¸
    if torch.cuda.is_available():
        print(f"   GPU ë©”ëª¨ë¦¬ í• ë‹¹: {torch.cuda.memory_allocated() / 1024**2:.2f} MB")
        torch.cuda.empty_cache()
        print(f"   ì •ë¦¬ í›„ GPU ë©”ëª¨ë¦¬: {torch.cuda.memory_allocated() / 1024**2:.2f} MB")

    # ì •ë¦¬
    import shutil
    shutil.rmtree(test_dir, ignore_errors=True)

    print("\nâœ… ìˆœì°¨ ì‹¤í–‰ í…ŒìŠ¤íŠ¸ í†µê³¼ (GPU ì¶©ëŒ ì—†ìŒ)")
    return True


def main():
    """ëª¨ë“  í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    print("="*60)
    print("GPU/CUDA ìµœì í™” í†µí•© í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print("="*60)

    # CUDA ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
    print(f"\nCUDA ì‚¬ìš© ê°€ëŠ¥: {torch.cuda.is_available()}")
    if torch.cuda.is_available():
        print(f"GPU ì´ë¦„: {torch.cuda.get_device_name(0)}")
        print(f"GPU ë©”ëª¨ë¦¬: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB")

    tests = [
        ("Deduplicator GPU", test_deduplicator_gpu),
        ("Deduplicator CPU Fallback", test_deduplicator_cpu_fallback),
        ("Classifier GPU", test_classifier_gpu),
        ("YoloDetector GPU", test_yolo_detector_gpu),
        ("ìˆœì°¨ ì‹¤í–‰ (ì¶©ëŒ í™•ì¸)", test_concurrent_gpu_usage),
    ]

    results = []
    for name, test_func in tests:
        try:
            success = test_func()
            results.append((name, success))
        except Exception as e:
            print(f"\nâŒ {name} í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
            results.append((name, False))

    # ìµœì¢… ê²°ê³¼
    print("\n" + "="*60)
    print("í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½")
    print("="*60)
    for name, success in results:
        status = "âœ… í†µê³¼" if success else "âŒ ì‹¤íŒ¨"
        print(f"{status}: {name}")

    total = len(results)
    passed = sum(1 for _, s in results if s)
    print(f"\nì´ {total}ê°œ í…ŒìŠ¤íŠ¸ ì¤‘ {passed}ê°œ í†µê³¼")

    if passed == total:
        print("\nğŸ‰ ëª¨ë“  í…ŒìŠ¤íŠ¸ í†µê³¼! GPU/CUDA ìµœì í™”ê°€ ì •ìƒ ì‘ë™í•©ë‹ˆë‹¤.")
        return 0
    else:
        print(f"\nâš ï¸  {total - passed}ê°œ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨")
        return 1


if __name__ == "__main__":
    sys.exit(main())
